{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbzF1VWunDZy"
   },
   "outputs": [],
   "source": [
    "!pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE8paD6vjzur"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"hf://datasets/gimmaru/ag_news/data/test-00000-of-00001-6ad17b7a040f1d68.parquet\")\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4ZRwviLfk3-0",
    "outputId": "f71b8e44-7738-4182-974c-480150e5c006"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4ujgLvXlq9a"
   },
   "outputs": [],
   "source": [
    "device = torch.device(1 if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQw1V9ccn2qm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "toberead = list(df['text'])\n",
    "random.shuffle(toberead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgJvgR5oqdBy"
   },
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "\n",
    "_ = base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4vb_JKvuy4C"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextOnlyDataset(Dataset):\n",
    "    def __init__(self, text_list):\n",
    "        self.text_list = text_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text_list[idx]\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "text_dataset = TextOnlyDataset(toberead)\n",
    "text_loader = DataLoader(text_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90,
     "referenced_widgets": [
      "6261eea27ed44afc99f6daac7d0c60f9",
      "fa9d5d6ef36944ed95af07d9bfedb98d",
      "ca78d39794db46f69636c9a1a9d39ad0",
      "31310741799e4cf89ec3f97e58ba76b7",
      "8edf08ddc0d04b7092dcb942d88a24c1",
      "c0235af80ea648dca78cd992fc701561",
      "08d02f173ce74f148d0a7003e60ac371",
      "38ca6510b70949f8b0d798b2246fd183",
      "86a41c86193b41479184fca92e4f64cf",
      "1b4c41c96f6b4d49b69cf2232843d703",
      "bf08a4989bc2490eb137b559e46fb617"
     ]
    },
    "id": "k_pPs7YNu5bR",
    "outputId": "c12d4956-012f-4826-d7a6-43868b0483cd"
   },
   "outputs": [],
   "source": [
    "embeddings_log = []\n",
    "text_log = []\n",
    "\n",
    "for text in tqdm(text_loader, desc=\"Extracting\", leave=False):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            embeddings = base_model(**encoded_input)[0][:, 0]\n",
    "            norm_embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "            embeddings_log.append(norm_embeddings.cpu())\n",
    "            text_log += list(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09SJTzGql7vK"
   },
   "outputs": [],
   "source": [
    "np_embeddings = torch.cat(embeddings_log).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMEQpXdd0h1p",
    "outputId": "5749148a-1bdc-4aa4-9444-5f6f37a5130a"
   },
   "outputs": [],
   "source": [
    "print(np_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poHrYqiIWEQ1",
    "outputId": "8567f376-fa9c-4825-bb7b-af1017449ec4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pairs, pair_labels):\n",
    "        self.pairs = pairs\n",
    "        self.labels = pair_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1, x2 = self.pairs[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(x1).float(), torch.tensor(x2).float(), torch.tensor(label).float()\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout_rate=0.05):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        out1 = self.forward_once(x1)\n",
    "        out2 = self.forward_once(x2)\n",
    "        return out1, out2\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        distances = F.pairwise_distance(output1, output2)\n",
    "        loss = (label * distances.pow(2) +\n",
    "                (1 - label) * F.relu(self.margin - distances).pow(2)).mean()\n",
    "        return loss\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_balanced_pairs(embeddings, pseudo_labels, num_pairs_per_class=1000):\n",
    "    label_to_indices = defaultdict(list)\n",
    "    for idx, label in enumerate(pseudo_labels):\n",
    "        label_to_indices[label].append(idx)\n",
    "\n",
    "    pairs = []\n",
    "    pair_labels = []\n",
    "\n",
    "    for label, indices in label_to_indices.items():\n",
    "        if len(indices) < 2:\n",
    "            continue\n",
    "        for _ in range(num_pairs_per_class):\n",
    "            i, j = random.sample(indices, 2)\n",
    "            pairs.append((embeddings[i], embeddings[j]))\n",
    "            pair_labels.append(1)\n",
    "\n",
    "    labels = list(label_to_indices.keys())\n",
    "    for _ in range(num_pairs_per_class * len(labels)):\n",
    "        l1, l2 = random.sample(labels, 2)\n",
    "        i = random.choice(label_to_indices[l1])\n",
    "        j = random.choice(label_to_indices[l2])\n",
    "        pairs.append((embeddings[i], embeddings[j]))\n",
    "        pair_labels.append(0)\n",
    "\n",
    "    return pairs, pair_labels\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "pseudo_labels = kmeans.fit_predict(np_embeddings)\n",
    "pairs, pair_labels = make_balanced_pairs(np_embeddings, pseudo_labels)\n",
    "\n",
    "dataset = PairDataset(pairs, pair_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "embedding_dim = np_embeddings.shape[-1]\n",
    "model = SiameseNetwork(input_dim=embedding_dim)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_x1, batch_x2, batch_labels in dataloader:\n",
    "        out1, out2 = model(batch_x1, batch_x2)\n",
    "        loss = criterion(out1, out2, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    improved_embeddings = model.forward_once(torch.tensor(np_embeddings).float()).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUJpcoFN60gh"
   },
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "siamesed_cluster_labels = kmeans.fit_predict(improved_embeddings)\n",
    "siamesed_cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5aFE1Uu78gg"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "\n",
    "combined_embs = np.vstack([improved_embeddings, siamesed_cluster_centers])\n",
    "combined_pca = pca.fit_transform(combined_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3F3i6CF70IA"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=50)\n",
    "combined_2d = tsne.fit_transform(combined_pca)\n",
    "\n",
    "embeddings_2d = combined_2d[:-n_clusters]\n",
    "centers_2d = combined_2d[-n_clusters:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E07JcmlC8Y8Q",
    "outputId": "9c420893-8530-4f9c-e6f8-22af2be2c76f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "import numpy as np\n",
    "if not isinstance(improved_embeddings, np.ndarray):\n",
    "    improved_embeddings = improved_embeddings.cpu().numpy()\n",
    "\n",
    "sil_score = silhouette_score(improved_embeddings, siamesed_cluster_labels)\n",
    "db_index = davies_bouldin_score(improved_embeddings, siamesed_cluster_labels)\n",
    "ch_index = calinski_harabasz_score(improved_embeddings, siamesed_cluster_labels)\n",
    "\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "print(f\"Davies-Bouldin Index: {db_index:.4f}\")\n",
    "print(f\"Calinski-Harabasz Index: {ch_index:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "pR4nrajI7_1J",
    "outputId": "065d6dda-fd89-428b-dda4-f08be5acb366"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for c in range(n_clusters):\n",
    "    idx = np.where(siamesed_cluster_labels == c)[0]\n",
    "    plt.scatter(embeddings_2d[idx,0],\n",
    "                embeddings_2d[idx,1],\n",
    "                s=5, label=f\"cluster {c}\")\n",
    "\n",
    "plt.scatter(centers_2d[:,0],\n",
    "            centers_2d[:,1],\n",
    "            marker=\"x\", s=100, c=\"k\", label=\"centers\")\n",
    "plt.legend()\n",
    "plt.title(\"Unsupervised t-SNE clustering\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
